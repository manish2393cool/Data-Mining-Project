{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rf_scratch",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "z9BYp0o4qwqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import sqrt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NkcP4xU_glY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def accuracy_metric_1(actual, predicted):\n",
        "  target_names = ['class 0/neutral', 'class 1/positive' , 'class 2/negative']\n",
        "  print(classification_report(actual, predicted, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hp-EhlqpKhwq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "  class_values = [row[column] for row in dataset]\n",
        "  unique = set(class_values)\n",
        "  lookup = dict()\n",
        "  for i, value in enumerate(unique):\n",
        "      lookup[value] = i\n",
        "  for row in dataset:\n",
        "      row[column] = lookup[row[column]]\n",
        "  return lookup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_oXb9eKKktU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "  correct = 0\n",
        "  for i in range(len(actual)):\n",
        "      if actual[i] == predicted[i]:\n",
        "          correct += 1\n",
        "  return correct / float(len(actual)) * 100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjQzSud0KmkY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "  folds = cross_validation_split(dataset, n_folds)\n",
        "  scores = list()\n",
        "  actual_acc = list()\n",
        "  pred_acc = list()\n",
        "  for fold in folds:\n",
        "      train_set = list(folds)\n",
        "      train_set.remove(fold)\n",
        "      train_set = sum(train_set, [])\n",
        "      test_set = list()\n",
        "      for row in fold:\n",
        "          row_copy = list(row)\n",
        "          test_set.append(row_copy)\n",
        "          row_copy[-1] = None\n",
        "      predicted = algorithm(train_set, test_set, *args)\n",
        "      actual = [row[-1] for row in fold]\n",
        "      accuracy = accuracy_metric(actual, predicted)\n",
        "      actual_acc.extend(actual)\n",
        "      pred_acc.extend(predicted)\n",
        "      scores.append(accuracy)\n",
        "  return scores,actual_acc,pred_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l5_v94EvKo3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split a dataset based on an attribute and an attribute value\n",
        "def test_split(index, value, dataset):\n",
        "  left, right = list(), list()\n",
        "  for row in dataset:\n",
        "      if row[index] < value:\n",
        "          left.append(row)\n",
        "      else:\n",
        "          right.append(row)\n",
        "  return left, right\n",
        "\n",
        "# Calculate the Gini index for a split dataset\n",
        "def gini_index(groups, class_values):\n",
        "  gini = 0.0\n",
        "  for class_value in class_values:\n",
        "      for group in groups:\n",
        "          size = len(group)\n",
        "          if size == 0:\n",
        "              continue;\n",
        "          proportion = [row[-1] for row in group].count(class_value) / float(size)\n",
        "          gini += (proportion * (1.0 - proportion))\n",
        "  return gini"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cL3WzLH_Ko1G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Select the best split point for a dataset\n",
        "def get_split(dataset, n_features):\n",
        "  class_values = list(set(row[-1] for row in dataset))\n",
        "  b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "  features = list()\n",
        "  while len(features) < n_features:\n",
        "      index = randrange(len(dataset[0])-1)\n",
        "      if index not in features:\n",
        "          features.append(index)\n",
        "  for index in features:\n",
        "      for row in dataset:\n",
        "          groups = test_split(index, row[index], dataset)\n",
        "          gini = gini_index(groups, class_values)\n",
        "          if gini < b_score:\n",
        "              b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "  return {'index':b_index, 'value':b_value, 'groups':b_groups}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lkile6bYK1Sk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a terminal node value\n",
        "def to_terminal(group):\n",
        "  outcomes = [row[-1] for row in group]\n",
        "  return max(set(outcomes), key=outcomes.count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "71K_NRN5qPK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create child splits for a node or make terminal\n",
        "def split(node, max_depth, min_size, n_features, depth):\n",
        "  left, right = node['groups']\n",
        "  del(node['groups'])\n",
        "  # check for a no split\n",
        "  if not left or not right:\n",
        "      node['left'] = node['right'] = to_terminal(left + right)\n",
        "      return\n",
        "  # check for max depth\n",
        "  if depth >= max_depth:\n",
        "      node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
        "      return\n",
        "  # process left child\n",
        "  if len(left) <= min_size:\n",
        "      node['left'] = to_terminal(left)\n",
        "  else:\n",
        "      node['left'] = get_split(left, n_features)\n",
        "      split(node['left'], max_depth, min_size, n_features, depth+1)\n",
        "  # process right child\n",
        "  if len(right) <= min_size:\n",
        "      node['right'] = to_terminal(right)\n",
        "  else:\n",
        "      node['right'] = get_split(right, n_features)\n",
        "      split(node['right'], max_depth, min_size, n_features, depth+1)\n",
        "\n",
        "# Build a decision tree\n",
        "def build_tree(train, max_depth, min_size, n_features):\n",
        "  root = get_split(dataset, n_features)\n",
        "  split(root, max_depth, min_size, n_features, 1)\n",
        "  return root\n",
        "\n",
        "# Make a prediction with a decision tree\n",
        "def predict(node, row):\n",
        "  if row[node['index']] < node['value']:\n",
        "      if isinstance(node['left'], dict):\n",
        "          return predict(node['left'], row)\n",
        "      else:\n",
        "          return node['left']\n",
        "  else:\n",
        "      if isinstance(node['right'], dict):\n",
        "          return predict(node['right'], row)\n",
        "      else:\n",
        "          return node['right']\n",
        "\n",
        "# Create a random subsample from the dataset with replacement\n",
        "def subsample(dataset, ratio):\n",
        "  sample = list()\n",
        "  n_sample = round(len(dataset) * ratio)\n",
        "  while len(sample) < n_sample:\n",
        "      index = randrange(len(dataset))\n",
        "      sample.append(dataset[index])\n",
        "  return sample\n",
        "\n",
        "# Make a prediction with a list of bagged trees\n",
        "def bagging_predict(trees, row):\n",
        "  predictions = [predict(tree, row) for tree in trees]\n",
        "  return max(set(predictions), key=predictions.count)\n",
        "\n",
        "# Random Forest Algorithm\n",
        "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
        "  trees = list()\n",
        "  for i in range(n_trees):\n",
        "      sample = subsample(train, sample_size)\n",
        "      tree = build_tree(sample, max_depth, min_size, n_features)\n",
        "      trees.append(tree)\n",
        "  predictions = [bagging_predict(trees, row) for row in test]\n",
        "  return(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gA47m4_wJhmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "  #print(\"CVS:---\",len(dataset))\n",
        "  dataset_split = list()\n",
        "  dataset_copy = list(dataset)\n",
        "  fold_size = len(dataset) / n_folds\n",
        "  for i in range(n_folds):\n",
        "      fold = list()\n",
        "      while len(fold) < fold_size and len(dataset_copy)!=0:\n",
        "        #print(len(dataset_copy))\n",
        "        index = randrange(len(dataset_copy))\n",
        "        fold.append(dataset_copy.pop(index))\n",
        "      dataset_split.append(fold)\n",
        "  #print(dataset_split)\n",
        "  return dataset_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n1mANzepq1rw",
        "colab_type": "code",
        "outputId": "9a53a197-589a-4629-abdd-31dabb082831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the random forest algorithm\n",
        "seed(1)\n",
        "import pandas as pd\n",
        "filename = '/content/sample_data/input_to_rf_dmm.csv'\n",
        "df = pd.read_csv(filename)\n",
        "dataset = df.loc[0:999].values.tolist()\n",
        "print(len(dataset))\n",
        "\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# evaluate algorithm\n",
        "n_folds = 2\n",
        "max_depth = 20\n",
        "min_size = 1\n",
        "sample_size = 1.0\n",
        "n_features = int(sqrt(len(dataset[0])-1))\n",
        "\n",
        "\n",
        "print(dataset[0:1])\n",
        "print([dataset[i][-1] for i in range(len(dataset))])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "[[-0.11889293044805528, 0.013231215998530388, -0.10595610737800598, 0.027026152238249782, -0.17433972656726834, -0.16811133921146393, -0.026528632268309597, 0.03839939832687378, -0.16921395063400269, 0.15977764129638672, -0.08318113535642624, 0.08099965751171112, -0.14149728417396545, 0.07562804222106934, -0.022622657939791683, -0.07053302228450775, -0.09800801426172256, 0.037071261554956436, -0.09942761063575743, -0.2110423445701599, 0.1078796088695526, -0.0015891707735136151, -0.13122117519378662, -0.1054023951292038, -0.11274103820323945, -0.06639648973941803, -0.18663763999938965, -0.2928256094455719, 0.05111819878220558, -0.031895995140075684, -0.008194200694561005, 0.17972390353679654, -0.24655677378177646, 0.07704958319664001, -0.2207634598016739, 0.14440061151981354, -0.1138717383146286, -0.09898284077644348, -0.11844801902770995, 0.05110904946923256, 0.13577492535114288, 0.2125098407268524, -0.1361551433801651, -0.035230103880167014, -0.1175428107380867, 0.12836629152297974, -0.0301420446485281, 0.07717893272638321, 0.15009482204914093, 0.11604742705821992, -0.06654027849435806, -0.05301271006464958, 0.04440022259950638, -0.20223422348499295, -0.030995013192296025, 0.0621621198952198, -0.012347398325800896, -0.1085423082113266, 0.02735321782529354, 0.0512927882373333, -0.10800917446613313, -0.13162200152873993, 0.02167754434049129, 0.040387328714132316, -0.03437275812029838, 0.08194328844547273, 0.018205178901553157, -0.16112183034420013, 0.13860881328582764, -0.07797840237617493, 0.0018875718815252183, 0.06058826670050621, -0.009393390268087387, 0.08987873047590256, 0.08385864645242691, 0.0800432413816452, 0.07644560933113098, 0.20673730969429016, 0.0005025084828957915, 0.1043584793806076, 0.2751816213130951, -0.12129682302474976, 0.1068272739648819, -0.022982850670814514, -0.08416997641324997, -0.07962894439697266, -0.03589978441596031, 0.07833496481180191, 0.08470380306243896, -0.07435587048530579, 0.0004567154392134398, -0.05630641430616379, 0.05089239776134491, -0.004688208922743797, 0.09585539996623993, -0.05592336878180504, -0.1324481964111328, -0.1706257462501526, 0.11859648674726485, -0.05909556522965431, -0.12652833759784698, -0.15352173149585724, -0.2551647424697876, 0.15876413881778714, -0.1747492551803589, -0.19469504058361053, -0.458019345998764, 0.08759956061840057, -0.34780827164649963, -0.19520799815654755, 0.3699435889720917, -0.5195584297180176, -0.14247773587703705, 0.01782054454088211, -0.438827395439148, -0.31026703119277954, 0.01140141859650612, 0.2340032160282135, 0.2773172855377197, -0.041400663554668427, -0.1019485667347908, -0.3192871510982513, -0.2826237678527832, 0.05072977393865585, -0.3394843339920044, -0.4398087561130524, 0.4233083426952362, -0.4727416336536408, -0.43557363748550415, -0.1417899876832962, 0.3127835988998413, -0.3182688057422638, 0.3875835835933685, -0.24092374742031095, 0.2743421196937561, 0.3334318697452545, -0.261277437210083, -0.17136427760124207, 0.045799944549798965, 0.0880691260099411, 0.20124784111976626, 0.3271654546260834, -0.1831270009279251, -0.11287857592105865, -0.2502286434173584, 0.17396247386932373, -0.03900856524705887, 0.28032124042510986, -0.3846502304077149, -0.40574780106544495, 0.07281292974948883, -0.34013956785202026, 0.7508204579353333, 0.06017038598656655, 0.1655903458595276, 0.3243662118911743, 0.08229034394025803, -0.6336502432823181, -0.3579925000667572, -0.2003493458032608, -0.014533176086843012, 0.11356927454471588, 0.21898968517780304, -0.08854079246520996, 0.0914546474814415, -0.5244104862213135, 0.08281416445970535, -0.08989816904067993, -0.2532511651515961, -0.12709976732730865, -0.2415710985660553, -0.8723440766334534, 0.32180073857307434, 0.22046984732151031, 0.3526197969913483, -0.11107203364372252, -0.4507366120815277, 0.2321353405714035, -0.2230444848537445, 0.05350969359278679, 0.5988585948944092, -0.4409104585647583, 0.3868148922920227, 0.0980539172887802, 0.4324516355991364, 0.11463595181703568, 0.01550054457038641, -0.3264506459236145, -0.1848749965429306, 0.06821046769618988, -0.2381647378206253, -0.2387892007827759, -0.1971607506275177, 0.16559214890003204, -0.22431638836860654, 0.1447707712650299, 0.16857686638832092, -0.33318156003952026, -0.26403337717056274, 0.18034353852272034, 1]]\n",
            "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 0, 1, 0, 1, 0, 0, 2, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 2, 2, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 1, 2, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 0, 1, 0, 2, 0, 1, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 0, 1, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 2, 0, 2, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 0, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 0, 2, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 2, 1, 2, 1, 0, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IzXGo0FkEYn1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for n_trees in [10]:\n",
        "  scores, actual_acc, pred_acc = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)\n",
        "  print('Trees: %d' % n_trees)\n",
        "  print('Scores: %s' % scores)\n",
        "  print(accuracy_metric_1(actual_acc, pred_acc))\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
